#+OPTIONS: ^:nil

* thanos diagram
  [[./png/thanos/diagram.png]]
  #+BEGIN_COMMENT
  #+BEGIN_SRC plantuml :file png/thanos/diagram.png
left to right direction
package "Metrics source" as data_source {
usecase "Node Exporter" as ne
usecase "TiDB" as tidb
usecase "TiKV" as tikv
usecase "PD" as pd
usecase "ng-monitoring" as ng
usecase "tidb_port_probe" as tp
usecase "monitor_port_probe" as mp
usecase "blackbox_exporter_probe" as bep
}
usecase "Prometheus" as prom
usecase "Thanos Sidecar" as ths
usecase "Thanos Store" as thst
usecase "Thanos Query" as thq

ne --> prom
tidb --> prom
tikv --> prom
pd --> prom
ng --> prom
tp --> prom
mp --> prom
bep --> prom

prom --> ths
ths --> (S3)
(S3) --> thst
thst --> thq
ths --> thq
thq --> (grafana)
  #+END_SRC
  #+END_COMMENT
* Prometheus
** Source data
   #+ATTR_HTML: :board 2 :rules all :frame boarder
   | Name                    |  Port | Comment                                                |
   |-------------------------+-------+--------------------------------------------------------|
   | Node Exporter           |  9100 | CPU, Memory, Disk                                      |
   | TiDB                    | 10080 | component metrics                                      |
   | TiKV                    | 20180 | component metrics                                      |
   | PD                      |  2379 | component metrics                                      |
   | ticdc                   |  8300 | component metrics                                      |
   |-------------------------+-------+--------------------------------------------------------|
   | ng-monitoring           | 12020 | https://github.com/pingcap/ng-monitoring               |
   |                         |       | TiDB Dashboard features - Continuous Profiling/Top SQL |
   |                         |       | https://docs.pingcap.com/tidb/stable/dashboard-faq     |
   |-------------------------+-------+--------------------------------------------------------|
   | tidb_port_probe         |       | TiDB/TiKV/PD port probe                                |
   | monitor_port_probe      |       | grafana/node_exporter/blackbox_exporter port probe     |
   | blackbox_exporter_probe |       | HTTP, HTTPS, DNS, TCP, ICMP and gRPC                   |

** Prometheus startup script
   #+BEGIN_SRC
OhMyTiUP$ more /home/admin/tidb/tidb-deploy/prometheus-9090/scripts/run_prometheus.sh
#!/bin/bash
set -e

DEPLOY_DIR=/home/admin/tidb/tidb-deploy/prometheus-9090
cd "${DEPLOY_DIR}" || exit 1

# WARNING: This file was auto-generated. Do not edit!
#          All your edit might be overwritten!

if [ -e "bin/ng-monitoring-server" ]; then
echo "#!/bin/bash

# WARNING: This file was auto-generated to restart ng-monitoring when fail. 
#          Do not edit! All your edit might be overwritten!

while true
do
    bin/ng-monitoring-server \
        --config /home/admin/tidb/tidb-deploy/prometheus-9090/conf/ngmonitoring.toml \
        >/dev/null 2>&1
    sleep 15s
done" > scripts/ng-wrapper.sh
fi
/bin/bash scripts/ng-wrapper.sh &

exec > >(tee -i -a "/home/admin/tidb/tidb-deploy/prometheus-9090/log/prometheus.log")
exec 2>&1
exec bin/prometheus/prometheus \
    --config.file="/home/admin/tidb/tidb-deploy/prometheus-9090/conf/prometheus.yml" \
    --web.listen-address=":9090" \
    --web.external-url="http://182.83.1.120:9090/" \
    --web.enable-admin-api \
    --web.enable-lifecycle \
    --log.level="info" \
    --storage.tsdb.path="/home/admin/tidb/tidb-data/prometheus-9090" \
    --storage.tsdb.retention="30d" \
    --storage.tsdb.min-block-duration="2h" \
    --storage.tsdb.max-block-duration="2h"
   #+END_SRC


* Thanos
** Install
  #+BEGIN_SRC
OhMyTiUP$ wget https://github.com/thanos-io/thanos/releases/download/v0.28.0/thanos-0.28.0.linux-amd64.tar.gz
  #+END_SRC

** Start the thanos sidecar
*** S3 config file
    #+BEGIN_SRC
type: S3
config:
  bucket: "jay-ticdc"
  endpoint: "s3.us-west-2.amazonaws.com"
  region: "us-west-2"
  aws_sdk_auth: false
  access_key: "XXXX2XXXXXX4XX4XXX7X"
  insecure: false
  signature_version2: false
  secret_key: "XXxXXXXXxxxxxxXXXXXXXXXXxxxddddddXXXXxxxpUBy0QVr"
  put_user_metadata: {}
  part_size: 67108864
    #+END_SRC
*** thanos sidecar startup
   #+BEGIN_SRC
   ./thanos sidecar --objstore.config-file=etc/s3.yaml --tsdb.path=/home/admin/tidb/tidb-data/prometheus-9090
   #+END_SRC

** thanos store
   #+BEGIN_SRC
OhMyTiUP$ ./thanos store --grpc-address=0.0.0.0:10921 --http-address=0.0.0.0:10922 --objstore.config-file=etc/s3.yaml
   #+END_SRC
   
** thanos query
   #+BEGIN_SRC
OhMyTiUP$ ./thanos query --grpc-address=0.0.0.0:10911 --store 0.0.0.0:10901 --store 0.0.0.0:10912
   #+END_SRC

* Grafana datasource update
 #+BEGIN_SRC
OhMyTiUP$ ls /home/admin/tidb/tidb-deploy/grafana-3000/provisioning/datasources
datasource.yml
OhMyTiUP
OhMyTiUP$ more datasource.yml
apiVersion: 1
datasources:
  - name: avrotest
    type: prometheus
    access: proxy
    url: http://182.83.1.120:9090
    withCredentials: false
    isDefault: false
    tlsAuth: false
    tlsAuthWithCACert: false
    version: 1
    editable: true
OhMyTiUP$ more datasource.yml
apiVersion: 1
datasources:
  - name: avrotest
    type: prometheus
    access: proxy
    url: http://182.83.1.120:10912
    withCredentials: false
    isDefault: false
    tlsAuth: false
    tlsAuthWithCACert: false
    version: 1
    editable: true
 #+END_SRC

** Grafana test
*** S3 block
   [[./png/thanos/0002.png]]
   [[./png/thanos/0003.png]]
   [[./png/thanos/0004.png]]
*** thanos data source
   [[./png/thanos/0005.png]]
*** Grafana metrics
   [[./png/thanos/0006.png]]

* TiDB prometheus estimation
** Prom-cli install
   #+BEGIN_SRC
OhMyTiUP$ wget https://github.com/nalbury/promql-cli/releases/download/v0.2.1/promql-v0.2.1-linux-amd64.tar.gz  
OhMyTiUP$ tar xvf promql-v0.2.1-linux-amd64.tar.gz
OhMyTiUP$ sudo mv promql /usr/local/bin/
OhMyTiUP$ promql --host "http://127.0.0.1:9090" 'sum(up) by (job) '
   #+END_SRC
** Prometheus sample size
   #+BEGIN_SRC
OhMyTiUP$ pwd
tidb-data/prometheus-9090

OhMyTiUP$ ls 01GFG76PZ6DMXE93ZB6QC6T8FY
chunks  index  meta.json  tombstones

OhMyTiUP$du -sh 01GFG76PZ6DMXE93ZB6QC6T8FY/chunks
36M     01GFG76PZ6DMXE93ZB6QC6T8FY/chunks

$ more 01GFGE2E75N4QTWG20CAV8G2JM/meta.json 
{
        "ulid": "01GFGE2E75N4QTWG20CAV8G2JM",
        "minTime": 1665914400024,
        "maxTime": 1665921600000,
        "stats": {
                "numSamples": 44786909,
                "numSeries": 90649,
                "numChunks": 373229
        },
        "compaction": {
                "level": 1,
                "sources": [
                        "01GFGE2E75N4QTWG20CAV8G2JM"
                ]
        },
        "version": 1
}
    #+END_SRC
    Sample size(bytes) = chuck size / # of Samples
In this example, the chuck size is 36MB while the number of samples is 44786909. So average sample size = 36*1024*1024/44786909 = 0.8 byte

** TiDB Component sample ratio
*** Python script to calculate the ratio of samples
   #+BEGIN_SRC python
      import requests
      import json
      import os
      
      # 01. Fetch all the metrics from prometheus
      _metrics = requests.get('http://127.0.0.1:9090/api/v1/label/__name__/values')
      
      _jsonMetrics = json.loads(_metrics.text)         # Load the return to json
      
      _samples = {}          # Keep count of samples {"tidb": 1000, "tikv": 2000, etc}
      for _metric in _jsonMetrics['data']:
          _type = _metric.split("_")[0]                # Take the metrics type. 
          if _type not in ['node', 'pd', 'probe', 'tidb', 'tiflash', 'tikv']:
              _type = 'other'
      
          # Get count of sample using below command
          ret = os.popen(f"promql --host http://127.0.0.1:9090 --output json 'sum(count_over_time({_metric}[10m]))'").read()
          _jsonRet = json.loads(ret)                  # convert to json object
      
          if _type not in _samples:
              _samples[_type] = int(_jsonRet[0]['value'][1])
          else:
              _samples[_type] += int(_jsonRet[0]['value'][1])
      
      print(f"The samples:  {_samples}")
    #+END_SRC
*** Python script run
    #+BEGIN_SRC
OhMyTiUP$ python3 count_samples.py
The samples:  {'other': 564701, 'node': 934487, 'pd': 198520, 'probe': 312715, 'tidb': 439320, 'tiflash': 1188477, 'tikv': 3117840} 
    #+END_SRC

*** Estimation
    | TiDB | TiKV        | PD | TiFlash | Monitor | AlertManager | Disk Size per 2 hour | month | Yearly |
    |------+-------------+----+---------+---------+--------------+----------------------+-------+--------|
    |    2 | 3           |  3 |       0 |       2 |            1 | 44 MB                | 15 GB | 180 GB |
    |    2 | 3(6)        |  3 |       0 |       2 |            1 | 49 MB                | 17 GB | 204 GB |
    |    2 | 3(6) + 3(3) |  3 |       0 |       2 |            1 | 61 MB                | 21 GB | 252 GB |
    |    2 | 3(6) + 3(3) |  3 |       4 |       2 |            1 | 84 MB                | 29 GB | 348 GB |

*** Use case
**** Number of instance
    + tidb - 38
    + tikv - 327
    + pd - 3
    + tiflash - 68
**** Instance Type of Prometheus
    + m5.4xlarge * 3
    + vCPU: 16
    + Memory: 64
    + retention: 15days
    + Disk: 1.5TB
    + resolution: 15s
    + Prmetheus restart: 4-5 hour
    + 200 physical servers
    
** How thanos help it    
    
    | metrics       | resolution |
    |---------------+------------|
    | < 40h         | raw(15s)   |
    | > 40h / < 10d | 5m         |
    | > 10d         | 1h         |
    [[https://thanos.io/tip/components/compact.md/][thanos compact]]

    
    1.5*1024 = 1536 -> 61GB/day -> 5GB/2 hours => 26MB

*** Sample ratio
    | Name | # of Nodes | # of samples | # of sample per node | Bytes( byte/sample) |
    |------+------------+--------------+----------------------+---------------------|
    | TiKV |          9 |      3117840 |               346426 |              346426 |
    | TiDB |          2 |       439320 |               219660 |              219660 |








   formula
   2,592,000 (seconds) * 18600 (samples/second) * 1.3 (bytes/sample) = 62,674,560,000 (bytes).
   needed_disk_space = retention_time_seconds * ingested_samples_per_second * bytes_per_sample

   Use the below command to calculate the number of samples.

   promql --host "http://127.0.0.1:9090" 'sum((count_over_time(process_cpu_seconds_total[1h])))

   
   #+BEGIN_SRC
OhMyTiUP$ curl -s  http://127.0.0.1:9090/api/v1/label/__name__/values | jq -r ".data[]" | wc -l
1479
   #+END_SRC

* TODO
** 3*pd + 2*tidb + 3*tikv
   {'ALERTS': 1010, 'br': 1520, 'etcd': 50720                , 'go': 29120, 'grpc': 182680, 'net': 1680, 'node': 483355, 'os': 240, 'pd': 149960, 'probe': 101648, 'process': 5240, 'promhttp': 3520, 'raft': 37440, 'scrape': 54158, 'tidb': 434920, 'tikv': 2052742, 'up': 13540}
** 3*pd + 2*tidb + 6*tikv
   {'ALERTS': 1200, 'br': 1520, 'etcd': 50694                , 'go': 33198, 'grpc': 182680, 'net': 1680, 'node': 628158, 'os': 240, 'pd': 166440, 'probe': 167212, 'process': 6560, 'promhttp': 4240, 'raft': 44520, 'scrape': 85828, 'tidb': 436727, 'tikv': 2526440, 'up': 21453}
** 3*pd + 4*tidb + 6*tikv
   {'ALERTS': 1416, 'br': 3040, 'etcd': 50719                , 'go': 44720, 'grpc': 182680, 'net': 1680, 'node': 724657, 'os': 240, 'pd': 208920, 'probe': 219912, 'process': 7680, 'promhttp': 5040, 'raft': 44520, 'scrape': 110923, 'tidb': 787116, 'tikv': 2526440, 'up': 27728}
   {'ALERTS': 1452, 'br': 3040, 'etcd': 50720                , 'go': 44718, 'grpc': 182680, 'net': 1680, 'node': 724667, 'os': 240, 'pd': 208920, 'probe': 219908, 'process': 7680, 'promhttp': 5040, 'raft': 44520, 'scrape': 110917, 'tidb': 787160, 'tikv': 2526326, 'up': 27731}
** 3*pd + 4*tidb + 6*tikv + 3*tiflash
   {'ALERTS': 1714, 'br': 3040, 'etcd': 50720, 'exposer': 840, 'go': 48796, 'grpc': 183280, 'net': 2240, 'node': 869464, 'os': 240, 'pd': 219440, 'probe': 312453, 'process': 8516, 'promhttp': 5760, 'raft': 44520, 'scrape': 155051, 'tidb': 787160, 'tiflash': 884160, 'tikv': 2526773, 'up': 38763}
** 3*pd + 4*tidb + 12*tikv(2 instance per server) + 3*tiflash
   {'ALERTS': 1730, 'br': 3040, 'etcd': 50720, 'exposer': 840, 'go': 48800, 'grpc': 183280, 'net': 2240, 'node': 870712, 'os': 240, 'pd': 243200, 'probe': 313202, 'process': 9480, 'promhttp': 5760, 'raft': 58572, 'scrape': 156512, 'tidb': 787158, 'tiflash': 883798, 'tikv': 3471680, 'up': 39127}
