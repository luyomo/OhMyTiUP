#+OPTIONS: ^:nil
* TiDB on AWS by TiUP
   + topo
     - general
       + tidb_version
         The tidb version to be installed on the aws
       + excluded_az
         The AZ to be excluded for the installation. The reason behind is that sometimes some AZ does not support specific instance type. This configuration is used to exclude the AZ.
       + included_az
         The AZ to be included for the installation. The reason behind that we do need to install the cluster in specific AZ.
       + network_type[public/private/nat: private]
         - public: Mostly it's used for workstation
         - nat: EC2 needs to access the internet
       + enable_audit_log:
         true: 
             If the version is greater than v.7.1.0, it use enterprse version to install.
             If the version is smaller than v7.1.0, no need to install plugins.
         false:
           install from network
     - tikv/pd/tidb...
       + count
         Number of nodes to be deployed
       + instance_type
         The instance type to be used for deployment
       + volume size
         The local volume size to be deployed
       + volume type
         gp2/gp3/io2/io3
       + iops
         The iops for the volume to be defined
** Audit log/Version >= v7.1.0
*** [[../embed/examples/aws/aws-tidb-advanced.yaml][yaml file preparation]]
 #+BEGIN_SRC
  workstation:
    cidr: 172.82.0.0/16                             # The cidr for the VPC
    imageid: ami-07d02ee1eeb0c996c                  # Workstation EC2 instance
    keyname: jay-us-east-01                         # Public key for workstation instance deployment
    keyfile: /home/pi/.ssh/jay-us-east-01.pem       # Private key to access the workstation
    volumeSize: 100                                 # disk size in the workstation
    enable_monitoring: enabled                      # The flag to decide whether the grafana is open on the workstation node
    instance_type: t2.medium                        # Instance type for PD component
  aws_topo_configs:
    general:
      # debian os
      imageid: ami-07d02ee1eeb0c996c                # Default image id for EC2
      keyname: jay-us-east-01                       # Public key to access the EC2 instance
      keyfile: /home/pi/.ssh/jay-us-east-01.pem     # Private key ti access the EC2 instance
      cidr: 172.83.0.0/16                           # The cidr for the VPC
      instance_type: t2.small                       # Default instance type
      enable_audit_log: true                        # Enable the audit log
      tidb_version: v7.1.0                          # TiDB version
      excluded_az:                                  # The AZ to be excluded for the subnets
        - us-east-1e
      network_type: nat                             # The flag to decide whether the nat is created in the TiDB VPC
    pd:
      instance_type: t2.small                       # Instance type for PD component
      count: 3                                      # Number of PD node to be deployed
    tidb:
      instance_type: t2.small                       # Instance type of tidb
      count: 2                                      # Number of TiDB node to be deployed
    tikv:
      -
        instance_type: t2.small                     # Instance type of TiKV
        count: 3                                    # Number of TiKV nodes to be deployed
        volumeSize: 50                              # Storage size for TiKV nodes (GB)
        volumeType: gp3                             # Storage type ex. gp2(default), gp3, io2
        iops: 2000                                  # Storage IOPS(Only for gp3, io2)
 #+END_SRC
*** Audit log/Version < v7.1.0
     #+BEGIN_SRC
  workstation:
    cidr: 172.82.0.0/16                             # The cidr for the VPC
    imageid: ami-07d02ee1eeb0c996c                  # Workstation EC2 instance
    keyname: jay-us-east-01                         # Public key for workstation instance deployment
    keyfile: /home/pi/.ssh/jay-us-east-01.pem       # Private key to access the workstation
    volumeSize: 100                                 # disk size in the workstation
    enable_monitoring: enabled                      # The flag to decide whether the grafana is open on the workstation node
    instance_type: t2.medium                        # Instance type for PD component
  aws_topo_configs:
    general:
      # debian os
      imageid: ami-07d02ee1eeb0c996c                # Default image id for EC2
      keyname: jay-us-east-01                       # Public key to access the EC2 instance
      keyfile: /home/pi/.ssh/jay-us-east-01.pem     # Private key ti access the EC2 instance
      cidr: 172.83.0.0/16                           # The cidr for the VPC
      instance_type: t2.small                       # Default instance type
      enable_audit_log: true                        # Enable the audit log
      tidb_version: v6.5.4                          # TiDB version
      excluded_az:                                  # The AZ to be excluded for the subnets
        - us-east-1e
      network_type: nat                             # The flag to decide whether the nat is created in the TiDB VPC
    pd:
      instance_type: t2.small                       # Instance type for PD component
      count: 3                                      # Number of PD node to be deployed
    tidb:
      instance_type: t2.small                       # Instance type of tidb
      count: 2                                      # Number of TiDB node to be deployed
    tikv:
      -
        instance_type: t2.small                     # Instance type of TiKV
        count: 3                                    # Number of TiKV nodes to be deployed
        volumeSize: 50                              # Storage size for TiKV nodes (GB)
        volumeType: gp3                             # Storage type ex. gp2(default), gp3, io2
        iops: 2000                                  # Storage IOPS(Only for gp3, io2)
 #+END_SRC
*** No audit log
     #+BEGIN_SRC
  workstation:
    cidr: 172.82.0.0/16                             # The cidr for the VPC
    imageid: ami-07d02ee1eeb0c996c                  # Workstation EC2 instance
    keyname: jay-us-east-01                         # Public key for workstation instance deployment
    keyfile: /home/pi/.ssh/jay-us-east-01.pem       # Private key to access the workstation
    volumeSize: 100                                 # disk size in the workstation
    enable_monitoring: enabled                      # The flag to decide whether the grafana is open on the workstation node
    instance_type: t2.medium                        # Instance type for PD component
  aws_topo_configs:
    general:
      # debian os
      imageid: ami-07d02ee1eeb0c996c                # Default image id for EC2
      keyname: jay-us-east-01                       # Public key to access the EC2 instance
      keyfile: /home/pi/.ssh/jay-us-east-01.pem     # Private key ti access the EC2 instance
      cidr: 172.83.0.0/16                           # The cidr for the VPC
      instance_type: t2.small                       # Default instance type
      tidb_version: v6.5.4                          # TiDB version
      excluded_az:                                  # The AZ to be excluded for the subnets
        - us-east-1e
      network_type: nat                             # The flag to decide whether the nat is created in the TiDB VPC
    pd:
      instance_type: t2.small                       # Instance type for PD component
      count: 3                                      # Number of PD node to be deployed
    tidb:
      instance_type: t2.small                       # Instance type of tidb
      count: 2                                      # Number of TiDB node to be deployed
    tikv:
      -
        instance_type: t2.small                     # Instance type of TiKV
        count: 3                                    # Number of TiKV nodes to be deployed
        volumeSize: 50                              # Storage size for TiKV nodes (GB)
        volumeType: gp3                             # Storage type ex. gp2(default), gp3, io2
        iops: 2000                                  # Storage IOPS(Only for gp3, io2)
 #+END_SRC

    
** Installation
   [[./png/tidb-on-aws/tidb-on-aws.01.png]]
   [[./png/tidb-on-aws/tidb-on-aws.02.png]]
** List all the resources
   [[./png/tidb-on-aws/tidb-on-aws.03.png]]
   [[./png/tidb-on-aws/tidb-on-aws.04.png]]
** Login to workstation to check TiDB connection
   [[./png/tidb-on-aws/tidb-on-aws.05.png]]
** Destroy the cluster and check
   [[./png/tidb-on-aws/tidb-on-aws.06.png]]
   [[./png/tidb-on-aws/tidb-on-aws.07.png]]
   
